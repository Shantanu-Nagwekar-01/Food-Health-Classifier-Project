{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNixET8ILBa7X1BdSm2GLky",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shantanu-Nagwekar-01/Food-Health-Classifier-Project/blob/main/Food_Health_Classifier_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgQwUtQ8lEeI",
        "outputId": "0cde257d-71d2-4816-dd34-d12f32c049a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-31 14:03:22--  https://huggingface.co/datasets/openfoodfacts/product-database/resolve/main/food.parquet?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.118, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/6716146cfc14a25260d39431/34de751e2ba40fcf930a48be931ffe001b29f4bd592f3c9029b5628b909428d7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251031T140322Z&X-Amz-Expires=3600&X-Amz-Signature=0b9e3d4ed78c9c2e313cf38742f3fee2622aea4b4811af129d7a8d4bca75c3ca&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27food.parquet%3B+filename%3D%22food.parquet%22%3B&x-id=GetObject&Expires=1761923002&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MTkyMzAwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NzE2MTQ2Y2ZjMTRhMjUyNjBkMzk0MzEvMzRkZTc1MWUyYmE0MGZjZjkzMGE0OGJlOTMxZmZlMDAxYjI5ZjRiZDU5MmYzYzkwMjliNTYyOGI5MDk0MjhkNyoifV19&Signature=A96MKDcEcjXPpl3wd6ttYIWFu7Z02gnqGIJYa85AJSDNeACkS2Ty52GKZwMcDjsx0xHQNmHUqcTbrcg115hTCkIT7c8ZiBER-sc2y3whAk8pbcbEkDlDu3XQ7Vs9UXxKgLvl2W6NglsTTpIshNA-OVqhVoHLzxWYzsngJEqOQLostp43aObT5YGn1vLUcUsCfTn%7Exsc16HGgizlchlMv4hapTdexNvLVkrz7Svjz24alTIDm4x-Vp3MMu3m%7EFy%7EkTv6syjb8iIhoTn8TkD5FJSSdM8SHcIaTLzs6nKxmtkMRRCxIgbiFxZ7LzUrGWPfh0R6Al43W-s-IZu9AC0cG0w__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-10-31 14:03:22--  https://cas-bridge.xethub.hf.co/xet-bridge-us/6716146cfc14a25260d39431/34de751e2ba40fcf930a48be931ffe001b29f4bd592f3c9029b5628b909428d7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251031T140322Z&X-Amz-Expires=3600&X-Amz-Signature=0b9e3d4ed78c9c2e313cf38742f3fee2622aea4b4811af129d7a8d4bca75c3ca&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27food.parquet%3B+filename%3D%22food.parquet%22%3B&x-id=GetObject&Expires=1761923002&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MTkyMzAwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NzE2MTQ2Y2ZjMTRhMjUyNjBkMzk0MzEvMzRkZTc1MWUyYmE0MGZjZjkzMGE0OGJlOTMxZmZlMDAxYjI5ZjRiZDU5MmYzYzkwMjliNTYyOGI5MDk0MjhkNyoifV19&Signature=A96MKDcEcjXPpl3wd6ttYIWFu7Z02gnqGIJYa85AJSDNeACkS2Ty52GKZwMcDjsx0xHQNmHUqcTbrcg115hTCkIT7c8ZiBER-sc2y3whAk8pbcbEkDlDu3XQ7Vs9UXxKgLvl2W6NglsTTpIshNA-OVqhVoHLzxWYzsngJEqOQLostp43aObT5YGn1vLUcUsCfTn%7Exsc16HGgizlchlMv4hapTdexNvLVkrz7Svjz24alTIDm4x-Vp3MMu3m%7EFy%7EkTv6syjb8iIhoTn8TkD5FJSSdM8SHcIaTLzs6nKxmtkMRRCxIgbiFxZ7LzUrGWPfh0R6Al43W-s-IZu9AC0cG0w__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.164.174.21, 18.164.174.68, 18.164.174.110, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.164.174.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4295034733 (4.0G)\n",
            "Saving to: ‘openfoodfacts.parquet’\n",
            "\n",
            "openfoodfacts.parqu 100%[===================>]   4.00G  73.9MB/s    in 71s     \n",
            "\n",
            "2025-10-31 14:04:34 (57.7 MB/s) - ‘openfoodfacts.parquet’ saved [4295034733/4295034733]\n",
            "\n",
            "File download complete!\n"
          ]
        }
      ],
      "source": [
        "# Download the parquet file using wget\n",
        "# The ?download=true is important\n",
        "!wget \"https://huggingface.co/datasets/openfoodfacts/product-database/resolve/main/food.parquet?download=true\" -O \"openfoodfacts.parquet\"\n",
        "\n",
        "print(\"File download complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nxYRCOclocx",
        "outputId": "e0e20b7d-a6ca-4cb8-aec0-b65da20dddb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# This does NOT load the 3.9GB file. It just reads the header.\n",
        "pq_file = pd.read_parquet('openfoodfacts.parquet', columns=['code']) # Load 1 tiny column to get metadata\n",
        "\n",
        "# Get and print all column names\n",
        "all_columns = pq_file.columns.to_list()\n",
        "print(\"All available columns:\")\n",
        "for col in all_columns:\n",
        "    print(col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2q9yEdwltb7",
        "outputId": "54219907-fab3-4862-b474-d1ccd4b61806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All available columns:\n",
            "code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow.parquet as pq\n",
        "\n",
        "# Open the file and get the schema\n",
        "parquet_file = pq.ParquetFile('openfoodfacts.parquet')\n",
        "print(\"All available columns:\")\n",
        "print(parquet_file.schema.names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu8E4sHomHVi",
        "outputId": "24e0d7ed-d410-4f0c-b6f3-d145ea4c9d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All available columns:\n",
            "['additives_n', 'element', 'element', 'element', 'brands', 'categories', 'element', 'ciqual_food_code', 'agribalyse_food_code', 'agribalyse_proxy_food_code', 'element', 'element', 'element', 'code', 'compared_to_category', 'complete', 'completeness', 'element', 'element', 'created_t', 'creator', 'element', 'element', 'element', 'element', 'ecoscore_data', 'ecoscore_grade', 'ecoscore_score', 'element', 'element', 'element', 'emb_codes', 'element', 'element', 'lang', 'text', 'key', 'imgid', 'rev', 'h', 'w', 'h', 'w', 'h', 'w', 'h', 'w', 'uploaded_t', 'uploader', 'element', 'element', 'ingredients_from_palm_oil_n', 'ingredients_n', 'element', 'ingredients_percent_analysis', 'element', 'lang', 'text', 'ingredients_with_specified_percent_n', 'ingredients_with_unspecified_percent_n', 'ingredients_without_ciqual_codes_n', 'element', 'ingredients', 'known_ingredients_n', 'element', 'labels', 'lang', 'element', 'element', 'last_editor', 'last_image_t', 'last_modified_by', 'last_modified_t', 'last_updated_t', 'link', 'element', 'element', 'manufacturing_places', 'max_imgid', 'element', 'element', 'new_additives_n', 'no_nutrition_data', 'nova_group', 'element', 'nova_groups', 'element', 'element', 'name', 'value', '100g', 'serving', 'unit', 'prepared_value', 'prepared_100g', 'prepared_serving', 'prepared_unit', 'nutriscore_grade', 'nutriscore_score', 'nutrition_data_per', 'obsolete', 'element', 'origins', 'field_name', 'timestamp', 'owner', 'packagings_complete', 'element', 'element', 'element', 'lang', 'text', 'packaging', 'material', 'number_of_units', 'quantity_per_unit', 'quantity_per_unit_unit', 'quantity_per_unit_value', 'recycling', 'shape', 'weight_measured', 'element', 'popularity_key', 'element', 'lang', 'text', 'product_quantity_unit', 'product_quantity', 'element', 'quantity', 'rev', 'scans_n', 'serving_quantity', 'serving_size', 'element', 'element', 'stores', 'element', 'unique_scans_n', 'unknown_ingredients_n', 'element', 'element', 'with_non_nutritive_sweeteners', 'with_sweeteners']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of the ONLY columns you want to load\n",
        "my_ml_columns = [\n",
        "    'product_name',\n",
        "    'nutriscore_grade',  # Maybe your target?\n",
        "    'energy-kcal_100g',\n",
        "    'fat_100g',\n",
        "    'proteins_100g',\n",
        "    'carbohydrates_100g',\n",
        "    'sugars_100g',\n",
        "    'fiber_100g',\n",
        "    'salt_100g'\n",
        "    # Add any other columns you need\n",
        "]\n",
        "\n",
        "print(\"Loading only the selected columns...\")\n",
        "\n",
        "# This is the magic. It only reads the data for these columns.\n",
        "df = pd.read_parquet(\n",
        "    'openfoodfacts.parquet',\n",
        "    columns=my_ml_columns\n",
        ")\n",
        "\n",
        "print(\"Data loaded successfully!\")\n",
        "\n",
        "# Now you have a DataFrame that is MUCH smaller\n",
        "df.info()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YOFWk86lmRA7",
        "outputId": "cbb2c792-b0ac-4ee0-e65a-5c3cc98e37e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading only the selected columns...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ArrowInvalid",
          "evalue": "No match for FieldRef.Name(energy-kcal_100g) in additives_n: int32\nadditives_tags: list<element: string>\nallergens_tags: list<element: string>\nbrands_tags: list<element: string>\nbrands: string\ncategories: string\ncategories_tags: list<element: string>\ncategories_properties: struct<ciqual_food_code: int32, agribalyse_food_code: int32, agribalyse_proxy_food_code: int32>\ncheckers_tags: list<element: string>\nciqual_food_name_tags: list<element: string>\ncities_tags: list<element: string>\ncode: string\ncompared_to_category: string\ncomplete: int32\ncompleteness: float\ncorrectors_tags: list<element: string>\ncountries_tags: list<element: string>\ncreated_t: int64\ncreator: string\ndata_quality_errors_tags: list<element: string>\ndata_quality_info_tags: list<element: string>\ndata_quality_warnings_tags: list<element: string>\ndata_sources_tags: list<element: string>\necoscore_data: string\necoscore_grade: string\necoscore_score: int32\necoscore_tags: list<element: string>\neditors: list<element: string>\nemb_codes_tags: list<element: string>\nemb_codes: string\nentry_dates_tags: list<element: string>\nfood_groups_tags: list<element: string>\ngeneric_name: list<element: struct<lang: string, text: string>>\nimages: list<element: struct<key: string, imgid: int32, rev: int32, sizes: struct<100: struct<h: int32, w: int32>, 200: struct<h: int32, w: int32>, 400: struct<h: int32, w: int32>, full: struct<h: int32, w: int32>>, uploaded_t: int64, uploader: string>>\ninformers_tags: list<element: string>\ningredients_analysis_tags: list<element: string>\ningredients_from_palm_oil_n: int32\ningredients_n: int32\ningredients_original_tags: list<element: string>\ningredients_percent_analysis: int32\ningredients_tags: list<element: string>\ningredients_text: list<element: struct<lang: string, text: string>>\ningredients_with_specified_percent_n: int32\ningredients_with_unspecified_percent_n: int32\ningredients_without_ciqual_codes_n: int32\ningredients_without_ciqual_codes: list<element: string>\ningredients: string\nknown_ingredients_n: int32\nlabels_tags: list<element: string>\nlabels: string\nlang: string\nlanguages_tags: list<element: string>\nlast_edit_dates_tags: list<element: string>\nlast_editor: string\nlast_image_t: int64\nlast_modified_by: string\nlast_modified_t: int64\nlast_updated_t: int64\nlink: string\nmain_countries_tags: list<element: string>\nmanufacturing_places_tags: list<element: string>\nmanufacturing_places: string\nmax_imgid: int32\nminerals_tags: list<element: string>\nmisc_tags: list<element: string>\nnew_additives_n: int32\nno_nutrition_data: bool\nnova_group: int32\nnova_groups_tags: list<element: string>\nnova_groups: string\nnucleotides_tags: list<element: string>\nnutrient_levels_tags: list<element: string>\nnutriments: list<element: struct<name: string, value: float, 100g: float, serving: float, unit: string, prepared_value: float, prepared_100g: float, prepared_serving: float, prepared_unit: string>>\nnutriscore_grade: string\nnutriscore_score: int32\nnutrition_data_per: string\nobsolete: bool\norigins_tags: list<element: string>\norigins: string\nowner_fields: list<element: struct<field_name: string, timestamp: int64>>\nowner: string\npackagings_complete: bool\npackaging_recycling_tags: list<element: string>\npackaging_shapes_tags: list<element: string>\npackaging_tags: list<element: string>\npackaging_text: list<element: struct<lang: string, text: string>>\npackaging: string\npackagings: list<element: struct<material: string, number_of_units: int64, quantity_per_unit: string, quantity_per_unit_unit: string, quantity_per_unit_value: string, recycling: string, shape: string, weight_measured: float>>\nphotographers: list<element: string>\npopularity_key: int64\npopularity_tags: list<element: string>\nproduct_name: list<element: struct<lang: string, text: string>>\nproduct_quantity_unit: string\nproduct_quantity: string\npurchase_places_tags: list<element: string>\nquantity: string\nrev: int32\nscans_n: int32\nserving_quantity: string\nserving_size: string\nstates_tags: list<element: string>\nstores_tags: list<element: string>\nstores: string\ntraces_tags: list<element: string>\nunique_scans_n: int32\nunknown_ingredients_n: int32\nunknown_nutrients_tags: list<element: string>\nvitamins_tags: list<element: string>\nwith_non_nutritive_sweeteners: int32\nwith_sweeteners: int32\n__fragment_index: int32\n__batch_index: int32\n__last_in_fragment: bool\n__filename: string",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3038740148.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# This is the magic. It only reads the data for these columns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m df = pd.read_parquet(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;34m'openfoodfacts.parquet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_ml_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             pa_table = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[1;32m   1841\u001b[0m         )\n\u001b[1;32m   1842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1843\u001b[0;31m     return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[0m\u001b[1;32m   1844\u001b[0m                         use_pandas_metadata=use_pandas_metadata)\n\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                 )\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m         table = self._dataset.to_table(\n\u001b[0m\u001b[1;32m   1486\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Dataset.scanner\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Scanner.from_dataset\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Scanner._make_scan_options\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset._populate_builder\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mArrowInvalid\u001b[0m: No match for FieldRef.Name(energy-kcal_100g) in additives_n: int32\nadditives_tags: list<element: string>\nallergens_tags: list<element: string>\nbrands_tags: list<element: string>\nbrands: string\ncategories: string\ncategories_tags: list<element: string>\ncategories_properties: struct<ciqual_food_code: int32, agribalyse_food_code: int32, agribalyse_proxy_food_code: int32>\ncheckers_tags: list<element: string>\nciqual_food_name_tags: list<element: string>\ncities_tags: list<element: string>\ncode: string\ncompared_to_category: string\ncomplete: int32\ncompleteness: float\ncorrectors_tags: list<element: string>\ncountries_tags: list<element: string>\ncreated_t: int64\ncreator: string\ndata_quality_errors_tags: list<element: string>\ndata_quality_info_tags: list<element: string>\ndata_quality_warnings_tags: list<element: string>\ndata_sources_tags: list<element: string>\necoscore_data: string\necoscore_grade: string\necoscore_score: int32\necoscore_tags: list<element: string>\neditors: list<element: string>\nemb_codes_tags: list<element: string>\nemb_codes: string\nentry_dates_tags: list<element: string>\nfood_groups_tags: list<element: string>\ngeneric_name: list<element: struct<lang: string, text: string>>\nimages: list<element: struct<key: string, imgid: int32, rev: int32, sizes: struct<100: struct<h: int32, w: int32>, 200: struct<h: int32, w: int32>, 400: struct<h: int32, w: int32>, full: struct<h: int32, w: int32>>, uploaded_t: int64, uploader: string>>\ninformers_tags: list<element: string>\ningredients_analysis_tags: list<element: string>\ningredients_from_palm_oil_n: int32\ningredients_n: int32\ningredients_original_tags: list<element: string>\ningredients_percent_analysis: int32\ningredients_tags: list<element: string>\ningredients_text: list<element: struct<lang: string, text: string>>\ningredients_with_specified_percent_n: int32\ningredients_with_unspecified_percent_n: int32\ningredients_without_ciqual_codes_n: int32\ningredients_without_ciqual_codes: list<element: string>\ningredients: string\nknown_ingredients_n: int32\nlabels_tags: list<element: string>\nlabels: string\nlang: string\nlanguages_tags: list<element: string>\nlast_edit_dates_tags: list<element: string>\nlast_editor: string\nlast_image_t: int64\nlast_modified_by: string\nlast_modified_t: int64\nlast_updated_t: int64\nlink: string\nmain_countries_tags: list<element: string>\nmanufacturing_places_tags: list<element: string>\nmanufacturing_places: string\nmax_imgid: int32\nminerals_tags: list<element: string>\nmisc_tags: list<element: string>\nnew_additives_n: int32\nno_nutrition_data: bool\nnova_group: int32\nnova_groups_tags: list<element: string>\nnova_groups: string\nnucleotides_tags: list<element: string>\nnutrient_levels_tags: list<element: string>\nnutriments: list<element: struct<name: string, value: float, 100g: float, serving: float, unit: string, prepared_value: float, prepared_100g: float, prepared_serving: float, prepared_unit: string>>\nnutriscore_grade: string\nnutriscore_score: int32\nnutrition_data_per: string\nobsolete: bool\norigins_tags: list<element: string>\norigins: string\nowner_fields: list<element: struct<field_name: string, timestamp: int64>>\nowner: string\npackagings_complete: bool\npackaging_recycling_tags: list<element: string>\npackaging_shapes_tags: list<element: string>\npackaging_tags: list<element: string>\npackaging_text: list<element: struct<lang: string, text: string>>\npackaging: string\npackagings: list<element: struct<material: string, number_of_units: int64, quantity_per_unit: string, quantity_per_unit_unit: string, quantity_per_unit_value: string, recycling: string, shape: string, weight_measured: float>>\nphotographers: list<element: string>\npopularity_key: int64\npopularity_tags: list<element: string>\nproduct_name: list<element: struct<lang: string, text: string>>\nproduct_quantity_unit: string\nproduct_quantity: string\npurchase_places_tags: list<element: string>\nquantity: string\nrev: int32\nscans_n: int32\nserving_quantity: string\nserving_size: string\nstates_tags: list<element: string>\nstores_tags: list<element: string>\nstores: string\ntraces_tags: list<element: string>\nunique_scans_n: int32\nunknown_ingredients_n: int32\nunknown_nutrients_tags: list<element: string>\nvitamins_tags: list<element: string>\nwith_non_nutritive_sweeteners: int32\nwith_sweeteners: int32\n__fragment_index: int32\n__batch_index: int32\n__last_in_fragment: bool\n__filename: string"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Update the column list\n",
        "my_ml_columns = [\n",
        "    'product_name',\n",
        "    'nutriscore_grade',\n",
        "    'nutriments'  # Load the parent column\n",
        "]\n",
        "\n",
        "print(\"Loading the parent 'nutriments' column...\")\n",
        "\n",
        "# This will now work without errors\n",
        "df = pd.read_parquet(\n",
        "    'openfoodfacts.parquet',\n",
        "    columns=my_ml_columns\n",
        ")\n",
        "\n",
        "print(\"✅ Data loaded successfully!\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn3UiTAsntaF",
        "outputId": "a6872b15-18f8-4a06-cc23-ace4f5cb411a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the parent 'nutriments' column...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. CORRECTED LIST of columns to load\n",
        "# We load the 'parent' columns that contain the data we want.\n",
        "my_ml_columns = [\n",
        "    'product_name',\n",
        "    'nutriscore_grade',\n",
        "    'nutriments',         # The parent column for all nutrition facts\n",
        "    'ingredients_text'    # The parent column for ingredients\n",
        "]\n",
        "\n",
        "print(\"Loading parent columns...\")\n",
        "df = pd.read_parquet(\n",
        "    'openfoodfacts.parquet',\n",
        "    columns=my_ml_columns\n",
        ")\n",
        "\n",
        "print(\"✅ Parent columns loaded successfully!\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXI68yhXoa6A",
        "outputId": "769b0f1d-583e-4326-fc9d-8b9045e55e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading parent columns...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"dask[dataframe]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goGu6zfXpNn4",
        "outputId": "6ca7bb8a-2930-42e1-b766-3bbdf4cfac3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.12/dist-packages (2025.5.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]) (8.3.0)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]) (25.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]) (6.0.3)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]) (18.1.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[dataframe]) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[dataframe]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[dataframe]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[dataframe]) (2025.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.12/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# This is the same 'unpack' function from before\n",
        "def unpack_nutriments(df_row):\n",
        "    nutriments_list = df_row['nutriments']\n",
        "    if nutriments_list is None:\n",
        "        return {}\n",
        "\n",
        "    unpacked_data = {}\n",
        "    for nutrient in nutriments_list:\n",
        "        if '100g' in nutrient and nutrient['name'] is not None:\n",
        "            # Create a key like 'fat_100g' from the nutrient's name\n",
        "            key = f\"{nutrient['name']}_100g\"\n",
        "            value = nutrient['100g']\n",
        "            unpacked_data[key] = value\n",
        "\n",
        "    return unpacked_data\n",
        "\n",
        "# This is a NEW function that Dask will run on each *chunk*\n",
        "def process_partition(chunk):\n",
        "    # 'chunk' is just a small pandas DataFrame\n",
        "\n",
        "    # 1. Unpack nutriments\n",
        "    nutriments_df = pd.json_normalize(chunk.apply(unpack_nutriments, axis=1))\n",
        "\n",
        "    # 2. Join the new columns\n",
        "    chunk = chunk.join(nutriments_df)\n",
        "\n",
        "    # 3. Clean the nested text columns\n",
        "    chunk['product_name'] = chunk['product_name'].str[0].str['text']\n",
        "    chunk['ingredients_text'] = chunk['ingredients_text'].str[0].str['text']\n",
        "\n",
        "    # 4. Drop the original messy columns\n",
        "    chunk = chunk.drop(columns=['nutriments'])\n",
        "\n",
        "    return chunk\n",
        "\n",
        "# --- This is the main Dask code ---\n",
        "\n",
        "# 1. Define the columns we want to PULL from the file\n",
        "my_ml_columns = [\n",
        "    'product_name',\n",
        "    'nutriscore_grade',\n",
        "    'nutriments',\n",
        "    'ingredients_text'\n",
        "]\n",
        "\n",
        "# 2. This is INSTANT and uses NO RAM.\n",
        "# It just creates a 'plan' for how to read the file.\n",
        "print(\"Creating Dask plan...\")\n",
        "ddf = dd.read_parquet(\n",
        "    'openfoodfacts.parquet',\n",
        "    columns=my_ml_columns\n",
        ")\n",
        "\n",
        "# 3. Define the *final* columns we want. This is for Dask's optimizer.\n",
        "# This list includes the new columns we are creating.\n",
        "final_columns = [\n",
        "    'product_name', 'nutriscore_grade', 'ingredients_text',\n",
        "    'fat_100g', 'sugars_100g', 'proteins_100g',\n",
        "    'carbohydrates_100g', 'salt_100g', 'fiber_100g',\n",
        "    'energy-kcal_100g'\n",
        "]\n",
        "\n",
        "# 4. Tell Dask to run our 'process_partition' function on every chunk\n",
        "# This is STILL lazy and hasn't run anything yet.\n",
        "print(\"Mapping processing function...\")\n",
        "ddf_clean = ddf.map_partitions(process_partition, meta=pd.DataFrame(columns=final_columns, dtype='object'))\n",
        "\n",
        "print(\"✅ Plan complete! Dask is ready to work.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ8a_qIMpQm5",
        "outputId": "cb526b1c-31ee-4ae7-8e1c-57554a1d7577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Dask plan...\n",
            "Mapping processing function...\n",
            "✅ Plan complete! Dask is ready to work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .compute() tells Dask: \"OK, actually do the work now\"\n",
        "print(ddf_clean.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "pecmgt8vpee-",
        "outputId": "55397ad4-fa8a-42a8-f746-fecc621eab25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The columns in the computed data do not match the columns in the provided metadata.\n  Extra:   ['0_100g', 'aaa_100g', 'acide-alphalinolenique_100g', 'acide-amine-essentiel-alanine_100g', 'acide-amine-essentiel-arginine_100g', 'acide-amine-essentiel-aspartique_100g', 'acide-amine-essentiel-glutamine_100g', 'acide-amine-essentiel-glycine_100g', 'acide-amine-essentiel-histidine_100g', 'acide-amine-essentiel-isoleucine_100g', 'acide-amine-essentiel-leucine_100g', 'acide-amine-essentiel-lysine_100g', 'acide-caprylique_100g', 'acide-gras-omega-3_100g', 'acide-gras-satures_100g', 'acide-linoleique_100g', 'acide-pantothenique-vitamine-b5_100g', 'acides-gras-insatures_100g', 'acides-gras-omega-3_100g', 'acides-gras-omega-6_100g', 'acidity_100g', 'acidos-grasos-trans_100g', 'added-sugars_100g', 'agmatine-sulfate_100g', 'alanin_100g', 'alcohol_100g', 'allulose_100g', 'alpha-linolenic-acid_100g', 'arachidic-acid_100g', 'arachidonic-acid_100g', 'arginin_100g', 'asparaginsaure_100g', 'attention-boisson-preparee-200-ml-deux-cuillieres-de-13-5g-la-valeur-indiquee-sur-l-emballage-pour-100-ml-et-non-100g-correspond-donc-aux-valeurs-pour-une-cuilliere-bombee-soit-13-5g_100g', 'b12_100g', 'bcaa_100g', 'beet-root-powder_100g', 'behenic-acid_100g', 'beta-carotene_100g', 'beta-glucane-d-avoine_100g', 'beurre-de-cacao-minimum_100g', 'beurre-de-cacao_100g', 'bicarbonate-de-sodium_100g', 'bicarbonate_100g', 'bicarbonatos_100g', 'bikarbonat_100g', 'biotin_100g', 'biotine-vitamine-b8-b7-h_100g', 'black-pepper-fruit-extract_100g', 'butyric-acid_100g', 'ca2_100g', 'cacao-minimum-dans-le-chocolat-au-lait_100g', 'cafeina_100g', 'caffeine_100g', 'calci_100g', 'calcium-ca_100g', 'calcium_100g', 'calories_100g', 'calsium_100g', 'capric-acid_100g', 'caprylic-acid_100g', 'carbohidratos_100g', 'carbohydrates-total_100g', 'carbon-footprint-from-known-ingredients_100g', 'carbon-footprint-from-meat-or-fish_100g', 'carbon-footprint_100g', 'carbonates_100g', 'carnitine_100g', 'casein_100g', 'caseines_100g', 'cellulose_100g', 'cereales_100g', 'chamomile_100g', 'chlore_100g', 'chloride_100g', 'chlorures_100g', 'cholesterol_100g', 'choline_100g', 'chromium_100g', 'citrate-monosodiquqe_100g', 'citrullin-malat_100g', 'cl_100g', 'cloruro_100g', 'cloruros_100g', 'cocoa_100g', 'colesterol_100g', 'collagen-meat-protein-ratio_100g', 'copper_100g', 'creatine_100g', 'cyclamate-de-sodium_100g', 'cystein_100g', 'd-glucuronolactone_100g', 'dan-shen-extract_100g', 'de-chlorid_100g', 'de-hydrogencarbonat_100g', 'de-nitrat_100g', 'de-sulfat_100g', 'dioxyde-de-soufre_100g', 'docosahexaenoic-acid_100g', 'dry-residue_100g', 'eicosapentaenoic-acid_100g', 'einfach-ungesattigte-fattsauren_100g', 'elaidic-acid_100g', 'en-0_100g', 'en-5-hydroxytryptophan_100g', 'en-cal_100g', 'en-dioxido-de-silicio_100g', 'en-erythritol_100g', 'en-extrait-sec-a-180-c_100g', 'en-fer_100g', 'en-fibra-dietetica_100g', 'en-fibres-du-son-de-ble_100g', 'en-iro_100g', 'en-isoflavones_100g', 'en-kwasy-tłuszczowe-jednonienasycone_100g', 'en-kwasy-tłuszczowe-wielonienasycone_100g', 'en-long-chain-omega-3-fatty-acids_100g', 'en-magnesio_100g', 'en-medium-chain-triglycerides_100g', 'en-new-galactose_100g', 'en-omega-3_100g', 'en-panthothenic_100g', 'en-phosphore_100g', 'en-sodio_100g', 'en-sucralose_100g', 'en-sucre-ajoute_100g', 'en-sucres-ajoutes_100g', 'en-sulfates_100g', 'en-thiamine_100g', 'en-total-sugars_100g', 'en-unite-alcool_100g', 'en-vatimin-a_100g', 'en-verdura_100g', 'en-vit_100g', 'en-vitamine-b6-pyridoxine_100g', 'en-vitamine-c-acide-ascorbique_100g', 'en-witamina-d_100g', 'en-xylitol_100g', 'energy-cal_100g', 'energy-from-fat_100g', 'energy-g_100g', 'energy-kj_100g', 'energy_100g', 'equivalent-as-salt_100g', 'erythritol_100g', 'es-boro_100g', 'extrait-de-peau-de-raisin_100g', 'extrait-sec-a-180_100g', 'fer_100g', 'fibra-dietetica_100g', 'fibra-insoluble_100g', 'fibra-soluble_100g', 'florur_100g', 'fluor_100g', 'fluorid_100g', 'fluoride_100g', 'folates_100g', 'fosfori_100g', 'fr-0_100g', 'fr-ammonium_100g', 'fr-chlorid_100g', 'fr-chorure_100g', 'fr-clcium_100g', 'fr-epa-dha_100g', 'fr-extrait-sec-a-180-c_100g', 'fr-fluor_100g', 'fr-hydrogencarbonat_100g', 'fr-nitrate_100g', 'fr-nitrates_100g', 'fr-nitrites_100g', 'fr-poisson_100g', 'fr-residu-sec-a-180-c_100g', 'fr-residu-sec_100g', 'fr-residu_100g', 'fr-sterols-vegetaux_100g', 'fr-strontium_100g', 'fr-stėrols-vegetaux_100g', 'fr-sulfate_100g', 'fr-sulfates_100g', 'fr-sulphate_100g', 'fr-teneur-totale-en-sels-mineraux_100g', 'fr-unite-d-alcool_100g', 'fr-xylitol_100g', 'fructose_100g', 'fruits-legumes-et-noix-minimum_100g', 'fruits-vegetables-and-nuts-minimum_100g', 'fruits-vegetables-legumes-estimate-from-ingredients_100g', 'fruits-vegetables-nuts-and-rapeseed-walnut-and-olive-oils_100g', 'fruits-vegetables-nuts-dried_100g', 'fruits-vegetables-nuts-estimate-from-ingredients_100g', 'fruits-vegetables-nuts-estimate_100g', 'fruits-vegetables-nuts_100g', 'galactose_100g', 'ginseng_100g', 'glucides assimilables_100g', 'glucose_100g', 'glutamin_100g', 'glutaminsaure_100g', 'gluten_100g', 'glycemic-index_100g', 'glycerol-monostearate_100g', 'glycin_100g', 'gondoic-acid_100g', 'graines_100g', 'grasas-saturadas_100g', 'grasas-totales_100g', 'guarana-seed-extract_100g', 'guarana_100g', 'hagebuttenextrakt_100g', 'hco3_100g', 'hesperidin_100g', 'histidin_100g', 'humidite_100g', 'hydrogencarbonat_100g', 'inositol_100g', 'insoluble-fiber_100g', 'inulin_100g', 'iodine_100g', 'iron_100g', 'isoleucin_100g', 'k1_100g', 'k_100g', 'klorur_100g', 'koffein_100g', 'l-carnitina_100g', 'l-citrulin_100g', 'l-isoleucine_100g', 'l-leucine_100g', 'l-norvalin_100g', 'l-taurin_100g', 'l-tyrosin_100g', 'l-valine_100g', 'lactose_100g', 'lauric-acid_100g', 'leucin_100g', 'linoleic-acid_100g', 'lysin-hcl_100g', 'lysin_100g', 'magnesium_100g', 'magnezyum_100g', 'maltodextrins_100g', 'maltose_100g', 'manganese_100g', 'mead-acid_100g', 'methionin_100g', 'mg2_100g', 'mineraux_100g', 'molibdeni_100g', 'molybdenum_100g', 'mono-unsaturated-fat_100g', 'monounsaturated-fat_100g', 'montanic-acid_100g', 'myristic-acid_100g', 'na_100g', 'nervonic-acid_100g', 'new_1_100g', 'new_2_100g', 'new_3_100g', 'nitrate_100g', 'nitrates_100g', 'nl-carbs_100g', 'no3_100g', 'nova-group_100g', 'nucleotides_100g', 'nutrition-score-fr_100g', 'nutrition-score_100g', 'oleic-acid_100g', 'omega-3-ala_100g', 'omega-3-dha-docosahexaenoic-acid_100g', 'omega-3-dha_100g', 'omega-3-epa-eicosapentaenoic-acid_100g', 'omega-3-epa_100g', 'omega-3-fat_100g', 'omega-3-other_100g', 'omega-3_100g', 'omega-6-fat_100g', 'omega-6la_100g', 'omega-9-fat_100g', 'otros-carbohidratos_100g', 'palmitic-acid_100g', 'panax-ginseng_100g', 'pantothenic-acid_100g', 'ph_100g', 'phenylalanin_100g', 'phosphates_100g', 'phosphore_100g', 'phosphorus_100g', 'phycocyanine_100g', 'phylloquinone_100g', 'poisson_100g', 'polydextrose_100g', 'polyols_100g', 'polyunsaturated-fat_100g', 'postasio_100g', 'potassium_100g', 'potasyum_100g', 'proin_100g', 'prolin_100g', 'protein-dry-substance_100g', 'protein_100g', 'proteins-dry-substance_100g', 'pt-alcaloides_100g', 'pt-extrato-seco_100g', 'pt-melatonina_100g', 'pt-papoila-da-california_100g', 'pt-valeriana_100g', 'pt-vitamina-b-6_100g', 'pt-vitamina-sais-minerais_100g', 'pt-vitaminha-b1_100g', 'residuo-seco_100g', 'riboflavine_100g', 'saccharinate-sodium_100g', 'salt-equivalent_100g', 'saturated-fat_100g', 'sel-mineraux_100g', 'selenium_100g', 'serin_100g', 'serum-proteins_100g', 'silica_100g', 'silice_100g', 'so4-2_100g', 'sodium-equivalent-sel_100g', 'sodium_100g', 'soluble-fiber_100g', 'sorbitol_100g', 'starch_100g', 'stearic-acid_100g', 'sucrose_100g', 'sulfat_100g', 'sulfate_100g', 'sulfates_100g', 'sulfatos_100g', 'sulphate_100g', 'taurine_100g', 'tcm_100g', 'tds_100g', 'thiamine_100g', 'threonin_100g', 'tilia-estrella_100g', 'total-carbs_100g', 'trans-fat_100g', 'traubenkernextrakt_100g', 'tryptophan_100g', 'tyrosin_100g', 'unite-alccol_100g', 'unite-alcool_100g', 'unite-d-alcool_100g', 'unitees-alcool_100g', 'valerian_100g', 'valin_100g', 'vit-b12_100g', 'vit-b1_100g', 'vit-b2_100g', 'vit-b5_100g', 'vit-b6_100g', 'vit-b9_100g', 'vitamin-a_100g', 'vitamin-b12-cobalamin_100g', 'vitamin-b12_100g', 'vitamin-b1_100g', 'vitamin-b2-riboflavin_100g', 'vitamin-b2_100g', 'vitamin-b6_100g', 'vitamin-b9_100g', 'vitamin-c_100g', 'vitamin-d_100g', 'vitamin-e_100g', 'vitamin-k_100g', 'vitamin-pp_100g', 'vitamine-a-comme-beta-carotene_100g', 'vitamine-a-retinol_100g', 'vitamine-a_100g', 'vitamine-b1-thiamine_100g', 'vitamine-b12-cobalamine_100g', 'vitamine-b12_100g', 'vitamine-b1_100g', 'vitamine-b2-riboflavine_100g', 'vitamine-b3-pp-niacine_100g', 'vitamine-b6-pyridoxine_100g', 'vitamine-b9-acide-folique_100g', 'vitamine-c-acide-ascorbique_100g', 'vitamine-c_100g', 'vitamine-d-d3-cholecalciferol_100g', 'vitamine-e-tocopherol_100g', 'vitamine-k1_100g', 'vitamine-k2_100g', 'vitamine-pp_100g', 'vitamines-b12_100g', 'vitamines-b2_100g', 'zinc_100g']\n  Missing: []",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-660809774.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# .compute() tells Dask: \"OK, actually do the work now\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddf_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dask/dataframe/dask_expr/_collection.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \"\"\"\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mcheck_matching_columns\u001b[0;34m(meta, actual)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;34mf\"\\nExpected: {meta.columns.tolist()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             )\n\u001b[0;32m--> 400\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;34m\"The columns in the computed data do not match\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;34m\" the columns in the provided metadata.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The columns in the computed data do not match the columns in the provided metadata.\n  Extra:   ['0_100g', 'aaa_100g', 'acide-alphalinolenique_100g', 'acide-amine-essentiel-alanine_100g', 'acide-amine-essentiel-arginine_100g', 'acide-amine-essentiel-aspartique_100g', 'acide-amine-essentiel-glutamine_100g', 'acide-amine-essentiel-glycine_100g', 'acide-amine-essentiel-histidine_100g', 'acide-amine-essentiel-isoleucine_100g', 'acide-amine-essentiel-leucine_100g', 'acide-amine-essentiel-lysine_100g', 'acide-caprylique_100g', 'acide-gras-omega-3_100g', 'acide-gras-satures_100g', 'acide-linoleique_100g', 'acide-pantothenique-vitamine-b5_100g', 'acides-gras-insatures_100g', 'acides-gras-omega-3_100g', 'acides-gras-omega-6_100g', 'acidity_100g', 'acidos-grasos-trans_100g', 'added-sugars_100g', 'agmatine-sulfate_100g', 'alanin_100g', 'alcohol_100g', 'allulose_100g', 'alpha-linolenic-acid_100g', 'arachidic-acid_100g', 'arachidonic-acid_100g', 'arginin_100g', 'asparaginsaure_100g', 'attention-boisson-preparee-200-ml-deux-cuillieres-de-13-5g-la-valeur-indiquee-sur-l-emballage-pour-100-ml-et-non-100g-correspond-donc-aux-valeurs-pour-une-cuilliere-bombee-soit-13-5g_100g', 'b12_100g', 'bcaa_100g', 'beet-root-powder_100g', 'behenic-acid_100g', 'beta-carotene_100g', 'beta-glucane-d-avoine_100g', 'beurre-de-cacao-minimum_100g', 'beurre-de-cacao_100g', 'bicarbonate-de-sodium_100g', 'bicarbonate_100g', 'bicarbonatos_100g', 'bikarbonat_100g', 'biotin_100g', 'biotine-vitamine-b8-b7-h_100g', 'black-pepper-fruit-extract_100g', 'butyric-acid_100g', 'ca2_100g', 'cacao-minimum-dans-...\n  Missing: []"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# This function is unchanged\n",
        "def unpack_nutriments(df_row):\n",
        "    nutriments_list = df_row['nutriments']\n",
        "    if nutriments_list is None:\n",
        "        return {}\n",
        "\n",
        "    unpacked_data = {}\n",
        "    for nutrient in nutriments_list:\n",
        "        if '100g' in nutrient and nutrient['name'] is not None:\n",
        "            key = f\"{nutrient['name']}_100g\"\n",
        "            value = nutrient['100g']\n",
        "            unpacked_data[key] = value\n",
        "\n",
        "    return unpacked_data\n",
        "\n",
        "# This function is also unchanged\n",
        "def process_partition(chunk):\n",
        "    nutriments_df = pd.json_normalize(chunk.apply(unpack_nutriments, axis=1))\n",
        "    chunk = chunk.join(nutriments_df)\n",
        "\n",
        "    chunk['product_name'] = chunk['product_name'].str[0].str['text']\n",
        "    chunk['ingredients_text'] = chunk['ingredients_text'].str[0].str['text']\n",
        "\n",
        "    chunk = chunk.drop(columns=['nutriments'])\n",
        "    return chunk\n",
        "\n",
        "# --- Main Dask Code ---\n",
        "\n",
        "# 1. Define the columns we want to PULL from the file\n",
        "my_ml_columns = [\n",
        "    'product_name',\n",
        "    'nutriscore_grade',\n",
        "    'nutriments',\n",
        "    'ingredients_text'\n",
        "]\n",
        "\n",
        "# 2. Create the initial lazy Dask plan (still instant)\n",
        "print(\"Creating Dask plan...\")\n",
        "ddf = dd.read_parquet(\n",
        "    'openfoodfacts.parquet',\n",
        "    columns=my_ml_columns\n",
        ")\n",
        "\n",
        "# 3. --- THIS IS THE FIX ---\n",
        "# We REMOVED the `meta` parameter.\n",
        "# Dask will now run on a sample chunk to figure out the full schema.\n",
        "print(\"Mapping processing function and inferring schema...\")\n",
        "ddf_with_all_nutrients = ddf.map_partitions(process_partition)\n",
        "\n",
        "print(\"✅ Schema inferred. Dask is ready.\")\n",
        "\n",
        "# 4. Now, define the final list of columns we *actually* want.\n",
        "final_ml_columns = [\n",
        "    'product_name',\n",
        "    'nutriscore_grade',\n",
        "    'ingredients_text',\n",
        "    'fat_100g',\n",
        "    'sugars_100g',\n",
        "    'proteins_100g',\n",
        "    'carbohydrates_100g',\n",
        "    'salt_100g',\n",
        "    'fiber_100g',\n",
        "    'energy-kcal_100g' # This was the original one that failed\n",
        "]\n",
        "\n",
        "# 5. Lazily select *only* the columns we want.\n",
        "# This avoids KeyErrors if a column (e.g., 'fiber_100g') doesn't exist.\n",
        "columns_to_select = [col for col in final_ml_columns if col in ddf_with_all_nutrients.columns]\n",
        "ddf_clean = ddf_with_all_nutrients[columns_to_select]\n",
        "\n",
        "print(f\"✅ Final ML DataFrame is ready with these columns: {columns_to_select}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P0ddisjrhrL",
        "outputId": "93163e79-b70e-47ef-d0ca-9c529e556325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Dask plan...\n",
            "Mapping processing function and inferring schema...\n",
            "✅ Schema inferred. Dask is ready.\n",
            "✅ Final ML DataFrame is ready with these columns: ['product_name', 'nutriscore_grade', 'ingredients_text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .compute() tells Dask: \"OK, actually do the work now\"\n",
        "print(ddf_clean.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "GlYhOhwfroo8",
        "outputId": "a7b30ddd-cd69-40f2-e4b7-bbaa3cdbbf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The columns in the computed data do not match the columns in the provided metadata.\n  Extra:   ['0_100g', 'aaa_100g', 'acide-alphalinolenique_100g', 'acide-amine-essentiel-alanine_100g', 'acide-amine-essentiel-arginine_100g', 'acide-amine-essentiel-aspartique_100g', 'acide-amine-essentiel-glutamine_100g', 'acide-amine-essentiel-glycine_100g', 'acide-amine-essentiel-histidine_100g', 'acide-amine-essentiel-isoleucine_100g', 'acide-amine-essentiel-leucine_100g', 'acide-amine-essentiel-lysine_100g', 'acide-caprylique_100g', 'acide-gras-omega-3_100g', 'acide-gras-satures_100g', 'acide-linoleique_100g', 'acide-pantothenique-vitamine-b5_100g', 'acides-gras-insatures_100g', 'acides-gras-omega-3_100g', 'acides-gras-omega-6_100g', 'acidity_100g', 'acidos-grasos-trans_100g', 'added-sugars_100g', 'agmatine-sulfate_100g', 'alanin_100g', 'alcohol_100g', 'allulose_100g', 'alpha-linolenic-acid_100g', 'arachidic-acid_100g', 'arachidonic-acid_100g', 'arginin_100g', 'asparaginsaure_100g', 'attention-boisson-preparee-200-ml-deux-cuillieres-de-13-5g-la-valeur-indiquee-sur-l-emballage-pour-100-ml-et-non-100g-correspond-donc-aux-valeurs-pour-une-cuilliere-bombee-soit-13-5g_100g', 'b12_100g', 'bcaa_100g', 'beet-root-powder_100g', 'behenic-acid_100g', 'beta-carotene_100g', 'beta-glucane-d-avoine_100g', 'beurre-de-cacao-minimum_100g', 'beurre-de-cacao_100g', 'bicarbonate-de-sodium_100g', 'bicarbonate_100g', 'bicarbonatos_100g', 'bikarbonat_100g', 'biotin_100g', 'biotine-vitamine-b8-b7-h_100g', 'black-pepper-fruit-extract_100g', 'butyric-acid_100g', 'ca2_100g', 'cacao-minimum-dans-le-chocolat-au-lait_100g', 'cafeina_100g', 'caffeine_100g', 'calci_100g', 'calcium-ca_100g', 'calcium_100g', 'calories_100g', 'calsium_100g', 'capric-acid_100g', 'caprylic-acid_100g', 'carbohidratos_100g', 'carbohydrates-total_100g', 'carbohydrates_100g', 'carbon-footprint-from-known-ingredients_100g', 'carbon-footprint-from-meat-or-fish_100g', 'carbon-footprint_100g', 'carbonates_100g', 'carnitine_100g', 'casein_100g', 'caseines_100g', 'cellulose_100g', 'cereales_100g', 'chamomile_100g', 'chlore_100g', 'chloride_100g', 'chlorures_100g', 'cholesterol_100g', 'choline_100g', 'chromium_100g', 'citrate-monosodiquqe_100g', 'citrullin-malat_100g', 'cl_100g', 'cloruro_100g', 'cloruros_100g', 'cocoa_100g', 'colesterol_100g', 'collagen-meat-protein-ratio_100g', 'copper_100g', 'creatine_100g', 'cyclamate-de-sodium_100g', 'cystein_100g', 'd-glucuronolactone_100g', 'dan-shen-extract_100g', 'de-chlorid_100g', 'de-hydrogencarbonat_100g', 'de-nitrat_100g', 'de-sulfat_100g', 'dioxyde-de-soufre_100g', 'docosahexaenoic-acid_100g', 'dry-residue_100g', 'eicosapentaenoic-acid_100g', 'einfach-ungesattigte-fattsauren_100g', 'elaidic-acid_100g', 'en-0_100g', 'en-5-hydroxytryptophan_100g', 'en-cal_100g', 'en-dioxido-de-silicio_100g', 'en-erythritol_100g', 'en-extrait-sec-a-180-c_100g', 'en-fer_100g', 'en-fibra-dietetica_100g', 'en-fibres-du-son-de-ble_100g', 'en-iro_100g', 'en-isoflavones_100g', 'en-kwasy-tłuszczowe-jednonienasycone_100g', 'en-kwasy-tłuszczowe-wielonienasycone_100g', 'en-long-chain-omega-3-fatty-acids_100g', 'en-magnesio_100g', 'en-medium-chain-triglycerides_100g', 'en-new-galactose_100g', 'en-omega-3_100g', 'en-panthothenic_100g', 'en-phosphore_100g', 'en-sodio_100g', 'en-sucralose_100g', 'en-sucre-ajoute_100g', 'en-sucres-ajoutes_100g', 'en-sulfates_100g', 'en-thiamine_100g', 'en-total-sugars_100g', 'en-unite-alcool_100g', 'en-vatimin-a_100g', 'en-verdura_100g', 'en-vit_100g', 'en-vitamine-b6-pyridoxine_100g', 'en-vitamine-c-acide-ascorbique_100g', 'en-witamina-d_100g', 'en-xylitol_100g', 'energy-cal_100g', 'energy-from-fat_100g', 'energy-g_100g', 'energy-kcal_100g', 'energy-kj_100g', 'energy_100g', 'equivalent-as-salt_100g', 'erythritol_100g', 'es-boro_100g', 'extrait-de-peau-de-raisin_100g', 'extrait-sec-a-180_100g', 'fat_100g', 'fer_100g', 'fiber_100g', 'fibra-dietetica_100g', 'fibra-insoluble_100g', 'fibra-soluble_100g', 'florur_100g', 'fluor_100g', 'fluorid_100g', 'fluoride_100g', 'folates_100g', 'fosfori_100g', 'fr-0_100g', 'fr-ammonium_100g', 'fr-chlorid_100g', 'fr-chorure_100g', 'fr-clcium_100g', 'fr-epa-dha_100g', 'fr-extrait-sec-a-180-c_100g', 'fr-fluor_100g', 'fr-hydrogencarbonat_100g', 'fr-nitrate_100g', 'fr-nitrates_100g', 'fr-nitrites_100g', 'fr-poisson_100g', 'fr-residu-sec-a-180-c_100g', 'fr-residu-sec_100g', 'fr-residu_100g', 'fr-sterols-vegetaux_100g', 'fr-strontium_100g', 'fr-stėrols-vegetaux_100g', 'fr-sulfate_100g', 'fr-sulfates_100g', 'fr-sulphate_100g', 'fr-teneur-totale-en-sels-mineraux_100g', 'fr-unite-d-alcool_100g', 'fr-xylitol_100g', 'fructose_100g', 'fruits-legumes-et-noix-minimum_100g', 'fruits-vegetables-and-nuts-minimum_100g', 'fruits-vegetables-legumes-estimate-from-ingredients_100g', 'fruits-vegetables-nuts-and-rapeseed-walnut-and-olive-oils_100g', 'fruits-vegetables-nuts-dried_100g', 'fruits-vegetables-nuts-estimate-from-ingredients_100g', 'fruits-vegetables-nuts-estimate_100g', 'fruits-vegetables-nuts_100g', 'galactose_100g', 'ginseng_100g', 'glucides assimilables_100g', 'glucose_100g', 'glutamin_100g', 'glutaminsaure_100g', 'gluten_100g', 'glycemic-index_100g', 'glycerol-monostearate_100g', 'glycin_100g', 'gondoic-acid_100g', 'graines_100g', 'grasas-saturadas_100g', 'grasas-totales_100g', 'guarana-seed-extract_100g', 'guarana_100g', 'hagebuttenextrakt_100g', 'hco3_100g', 'hesperidin_100g', 'histidin_100g', 'humidite_100g', 'hydrogencarbonat_100g', 'inositol_100g', 'insoluble-fiber_100g', 'inulin_100g', 'iodine_100g', 'iron_100g', 'isoleucin_100g', 'k1_100g', 'k_100g', 'klorur_100g', 'koffein_100g', 'l-carnitina_100g', 'l-citrulin_100g', 'l-isoleucine_100g', 'l-leucine_100g', 'l-norvalin_100g', 'l-taurin_100g', 'l-tyrosin_100g', 'l-valine_100g', 'lactose_100g', 'lauric-acid_100g', 'leucin_100g', 'linoleic-acid_100g', 'lysin-hcl_100g', 'lysin_100g', 'magnesium_100g', 'magnezyum_100g', 'maltodextrins_100g', 'maltose_100g', 'manganese_100g', 'mead-acid_100g', 'methionin_100g', 'mg2_100g', 'mineraux_100g', 'molibdeni_100g', 'molybdenum_100g', 'mono-unsaturated-fat_100g', 'monounsaturated-fat_100g', 'montanic-acid_100g', 'myristic-acid_100g', 'na_100g', 'nervonic-acid_100g', 'new_1_100g', 'new_2_100g', 'new_3_100g', 'nitrate_100g', 'nitrates_100g', 'nl-carbs_100g', 'no3_100g', 'nova-group_100g', 'nucleotides_100g', 'nutrition-score-fr_100g', 'nutrition-score_100g', 'oleic-acid_100g', 'omega-3-ala_100g', 'omega-3-dha-docosahexaenoic-acid_100g', 'omega-3-dha_100g', 'omega-3-epa-eicosapentaenoic-acid_100g', 'omega-3-epa_100g', 'omega-3-fat_100g', 'omega-3-other_100g', 'omega-3_100g', 'omega-6-fat_100g', 'omega-6la_100g', 'omega-9-fat_100g', 'otros-carbohidratos_100g', 'palmitic-acid_100g', 'panax-ginseng_100g', 'pantothenic-acid_100g', 'ph_100g', 'phenylalanin_100g', 'phosphates_100g', 'phosphore_100g', 'phosphorus_100g', 'phycocyanine_100g', 'phylloquinone_100g', 'poisson_100g', 'polydextrose_100g', 'polyols_100g', 'polyunsaturated-fat_100g', 'postasio_100g', 'potassium_100g', 'potasyum_100g', 'proin_100g', 'prolin_100g', 'protein-dry-substance_100g', 'protein_100g', 'proteins-dry-substance_100g', 'proteins_100g', 'pt-alcaloides_100g', 'pt-extrato-seco_100g', 'pt-melatonina_100g', 'pt-papoila-da-california_100g', 'pt-valeriana_100g', 'pt-vitamina-b-6_100g', 'pt-vitamina-sais-minerais_100g', 'pt-vitaminha-b1_100g', 'residuo-seco_100g', 'riboflavine_100g', 'saccharinate-sodium_100g', 'salt-equivalent_100g', 'salt_100g', 'saturated-fat_100g', 'sel-mineraux_100g', 'selenium_100g', 'serin_100g', 'serum-proteins_100g', 'silica_100g', 'silice_100g', 'so4-2_100g', 'sodium-equivalent-sel_100g', 'sodium_100g', 'soluble-fiber_100g', 'sorbitol_100g', 'starch_100g', 'stearic-acid_100g', 'sucrose_100g', 'sugars_100g', 'sulfat_100g', 'sulfate_100g', 'sulfates_100g', 'sulfatos_100g', 'sulphate_100g', 'taurine_100g', 'tcm_100g', 'tds_100g', 'thiamine_100g', 'threonin_100g', 'tilia-estrella_100g', 'total-carbs_100g', 'trans-fat_100g', 'traubenkernextrakt_100g', 'tryptophan_100g', 'tyrosin_100g', 'unite-alccol_100g', 'unite-alcool_100g', 'unite-d-alcool_100g', 'unitees-alcool_100g', 'valerian_100g', 'valin_100g', 'vit-b12_100g', 'vit-b1_100g', 'vit-b2_100g', 'vit-b5_100g', 'vit-b6_100g', 'vit-b9_100g', 'vitamin-a_100g', 'vitamin-b12-cobalamin_100g', 'vitamin-b12_100g', 'vitamin-b1_100g', 'vitamin-b2-riboflavin_100g', 'vitamin-b2_100g', 'vitamin-b6_100g', 'vitamin-b9_100g', 'vitamin-c_100g', 'vitamin-d_100g', 'vitamin-e_100g', 'vitamin-k_100g', 'vitamin-pp_100g', 'vitamine-a-comme-beta-carotene_100g', 'vitamine-a-retinol_100g', 'vitamine-a_100g', 'vitamine-b1-thiamine_100g', 'vitamine-b12-cobalamine_100g', 'vitamine-b12_100g', 'vitamine-b1_100g', 'vitamine-b2-riboflavine_100g', 'vitamine-b3-pp-niacine_100g', 'vitamine-b6-pyridoxine_100g', 'vitamine-b9-acide-folique_100g', 'vitamine-c-acide-ascorbique_100g', 'vitamine-c_100g', 'vitamine-d-d3-cholecalciferol_100g', 'vitamine-e-tocopherol_100g', 'vitamine-k1_100g', 'vitamine-k2_100g', 'vitamine-pp_100g', 'vitamines-b12_100g', 'vitamines-b2_100g', 'zinc_100g']\n  Missing: []",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-660809774.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# .compute() tells Dask: \"OK, actually do the work now\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddf_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dask/dataframe/dask_expr/_collection.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \"\"\"\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mcheck_matching_columns\u001b[0;34m(meta, actual)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;34mf\"\\nExpected: {meta.columns.tolist()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             )\n\u001b[0;32m--> 400\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;34m\"The columns in the computed data do not match\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;34m\" the columns in the provided metadata.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The columns in the computed data do not match the columns in the provided metadata.\n  Extra:   ['0_100g', 'aaa_100g', 'acide-alphalinolenique_100g', 'acide-amine-essentiel-alanine_100g', 'acide-amine-essentiel-arginine_100g', 'acide-amine-essentiel-aspartique_100g', 'acide-amine-essentiel-glutamine_100g', 'acide-amine-essentiel-glycine_100g', 'acide-amine-essentiel-histidine_100g', 'acide-amine-essentiel-isoleucine_100g', 'acide-amine-essentiel-leucine_100g', 'acide-amine-essentiel-lysine_100g', 'acide-caprylique_100g', 'acide-gras-omega-3_100g', 'acide-gras-satures_100g', 'acide-linoleique_100g', 'acide-pantothenique-vitamine-b5_100g', 'acides-gras-insatures_100g', 'acides-gras-omega-3_100g', 'acides-gras-omega-6_100g', 'acidity_100g', 'acidos-grasos-trans_100g', 'added-sugars_100g', 'agmatine-sulfate_100g', 'alanin_100g', 'alcohol_100g', 'allulose_100g', 'alpha-linolenic-acid_100g', 'arachidic-acid_100g', 'arachidonic-acid_100g', 'arginin_100g', 'asparaginsaure_100g', 'attention-boisson-preparee-200-ml-deux-cuillieres-de-13-5g-la-valeur-indiquee-sur-l-emballage-pour-100-ml-et-non-100g-correspond-donc-aux-valeurs-pour-une-cuilliere-bombee-soit-13-5g_100g', 'b12_100g', 'bcaa_100g', 'beet-root-powder_100g', 'behenic-acid_100g', 'beta-carotene_100g', 'beta-glucane-d-avoine_100g', 'beurre-de-cacao-minimum_100g', 'beurre-de-cacao_100g', 'bicarbonate-de-sodium_100g', 'bicarbonate_100g', 'bicarbonatos_100g', 'bikarbonat_100g', 'biotin_100g', 'biotine-vitamine-b8-b7-h_100g', 'black-pepper-fruit-extract_100g', 'butyric-acid_100g', 'ca2_100g', 'cacao-minimum-dans-...\n  Missing: []"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. DEFINE OUR FINAL COLUMNS FIRST ---\n",
        "# This is our \"contract\". This is all we want in the end.\n",
        "final_ml_columns = [\n",
        "    'product_name',\n",
        "    'nutriscore_grade',\n",
        "    'ingredients_text',\n",
        "    'fat_100g',\n",
        "    'sugars_100g',\n",
        "    'proteins_100g',\n",
        "    'carbohydrates_100g',\n",
        "    'salt_100g',\n",
        "    'fiber_100g',\n",
        "    'energy-kcal_100g'\n",
        "]\n",
        "\n",
        "# This is a helper function, same as before\n",
        "def unpack_nutriments(df_row):\n",
        "    nutriments_list = df_row['nutriments']\n",
        "    if nutriments_list is None:\n",
        "        return {}\n",
        "\n",
        "    unpacked_data = {}\n",
        "    for nutrient in nutriments_list:\n",
        "        if '100g' in nutrient and nutrient['name'] is not None:\n",
        "            # We must handle the 'energy-kcal' case\n",
        "            if nutrient['name'] == 'energy-kcal':\n",
        "                 key = 'energy-kcal_100g'\n",
        "            else:\n",
        "                 key = f\"{nutrient['name']}_100g\"\n",
        "            value = nutrient['100g']\n",
        "            unpacked_data[key] = value\n",
        "\n",
        "    return unpacked_data\n",
        "\n",
        "# --- 2. MODIFIED PROCESSING FUNCTION ---\n",
        "def process_partition(chunk):\n",
        "    # Unpack nutriments (creates a DataFrame with random nutrient columns)\n",
        "    nutriments_df = pd.json_normalize(chunk.apply(unpack_nutriments, axis=1))\n",
        "\n",
        "    # Join the new columns\n",
        "    chunk = chunk.join(nutriments_df)\n",
        "\n",
        "    # Clean the nested text columns\n",
        "    chunk['product_name'] = chunk['product_name'].str[0].str['text']\n",
        "    chunk['ingredients_text'] = chunk['ingredients_text'].str[0].str['text']\n",
        "\n",
        "    # --- THIS IS THE CRITICAL FIX ---\n",
        "    # We force the chunk to only have columns from our final list.\n",
        "    # We add any columns that are in our list but not in this chunk (filling with NaN).\n",
        "    # We drop all the extra columns (like 'acide-alphalinolenique_100g').\n",
        "    chunk = chunk.reindex(columns=final_ml_columns, fill_value=np.nan)\n",
        "\n",
        "    return chunk\n",
        "\n",
        "# --- 3. MAIN DASK CODE ---\n",
        "\n",
        "# Define the columns we need to PULL from the file\n",
        "my_ml_columns = [\n",
        "    'product_name',\n",
        "    'nutriscore_grade',\n",
        "    'nutriments',\n",
        "    'ingredients_text'\n",
        "]\n",
        "\n",
        "# Create the initial lazy Dask plan\n",
        "print(\"Creating Dask plan...\")\n",
        "ddf = dd.read_parquet(\n",
        "    'openfoodfacts.parquet',\n",
        "    columns=my_ml_columns\n",
        ")\n",
        "\n",
        "# Define the 'meta' (the \"contract\") for Dask\n",
        "# This tells Dask EXACTLY what the output of our function will be\n",
        "meta_contract = pd.DataFrame(columns=final_ml_columns, dtype='object')\n",
        "\n",
        "# Map the processing function\n",
        "print(\"Mapping processing function...\")\n",
        "\n",
        "# --- THIS IS THE CORRECTED LINE ---\n",
        "# We call .map_partitions() on our 'ddf' object\n",
        "ddf_clean = ddf.map_partitions(process_partition, meta=meta_contract)\n",
        "\n",
        "print(\"✅ Plan complete! Dask is ready to work.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ4iTfYvsW8r",
        "outputId": "6f6a0a27-9bd9-4b0c-8f0d-dc4fc249009d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Dask plan...\n",
            "Mapping processing function...\n",
            "✅ Plan complete! Dask is ready to work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will finally work!\n",
        "print(\"Computing head...\")\n",
        "print(ddf_clean.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_xu2tcetcCX",
        "outputId": "c53c7184-8818-45bb-cadd-0f5058c29d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing head...\n",
            "                                        product_name nutriscore_grade  \\\n",
            "0  Véritable pâte à tartiner noisettes chocolat noir                e   \n",
            "1                               Chamomile Herbal Tea          unknown   \n",
            "2                     Lagg's, herbal tea, peppermint          unknown   \n",
            "3                                 Linden Flowers Tea          unknown   \n",
            "4                               Herbal Tea, Hibiscus          unknown   \n",
            "\n",
            "     ingredients_text  fat_100g  sugars_100g  proteins_100g  \\\n",
            "0                 NaN      48.0         32.0       8.000000   \n",
            "1  CHAMOMILE FLOWERS.       NaN          NaN            NaN   \n",
            "2         Peppermint.       0.0          NaN       0.000000   \n",
            "3     LINDEN FLOWERS.       NaN          NaN            NaN   \n",
            "4   Hibiscus flowers.       0.0          NaN      66.669998   \n",
            "\n",
            "   carbohydrates_100g  salt_100g  fiber_100g  energy-kcal_100g  \n",
            "0               36.00    0.01000         NaN             617.0  \n",
            "1                 NaN        NaN         NaN               NaN  \n",
            "2                1.47    0.01000         NaN               0.0  \n",
            "3                 NaN        NaN         NaN               NaN  \n",
            "4               60.00    0.33782         NaN             267.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- This is your next step ---\n",
        "\n",
        "print(\"Creating 10% sample...\")\n",
        "\n",
        "# This tells Dask to run the *entire* pipeline and\n",
        "# pull 10% of the clean rows into a new pandas DataFrame\n",
        "df_sample = ddf_clean.sample(frac=0.1).compute()\n",
        "\n",
        "print(\"✅ Sample created! You can now use 'df_sample' with pandas and scikit-learn.\")\n",
        "\n",
        "# Inspect your new pandas DataFrame\n",
        "df_sample.info()\n",
        "print(df_sample.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxjLijChucvS",
        "outputId": "06636709-750e-439b-ef3f-c94b7325fc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating 10% sample...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# This tries to create the sample.\n",
        "# If it fails, it means 'ddf_clean' is no longer in memory.\n",
        "# You must re-run the Dask processing code from our previous step,\n",
        "# then run this cell again.\n",
        "try:\n",
        "    print(\"Creating a 1% sample...\")\n",
        "    df_sample = ddf_clean.sample(frac=0.01).compute()\n",
        "    print(\"✅ 1% sample created!\")\n",
        "\n",
        "    # Show memory usage and columns\n",
        "    df_sample.info()\n",
        "\n",
        "except NameError:\n",
        "    print(\"❌ Error: 'ddf_clean' not found.\")\n",
        "    print(\"Please re-run the Dask processing code from the previous step.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppu1X2_AxVT_",
        "outputId": "8670c619-b7f2-44e8-b00e-06e8e73447ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a 1% sample...\n"
          ]
        }
      ]
    }
  ]
}